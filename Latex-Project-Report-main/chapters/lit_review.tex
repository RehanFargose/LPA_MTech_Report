\chapter{Literature Review}{\label{ch:lit_review}}

% Textual literature review (synthesis)
\section*{Textual Synthesis}
\noindent The use of AI-ML in the Legal field has attracted considerable attention. Since the rise of NLP and LLMs it has become feasible to process large amounts of data and produce results in line with Verdict predictions, Summarization, Precedent finding. There is a large amount of legal data from the last century that has been scanned and digitized which has led to the rise of a Sub-field in the NLP domain known as LJP (Legal Judgement Prediction) \cite{b1} to make the judiciary more efficient and faster. PLMs such as LegalBERT tend to outperform with 88.3 MaF compared to less than 80.2 MaF for generic LLMs and HANs. For documents exceeding 512 tokens, the Longformer-based Lawformer achieved superior results in criminal cases (95.4 MaF for charges) by capturing long-distance dependencies. Integrated frameworks like LADAN + MPBFN reach 96.60\% accuracy for article prediction and 96.42\% for charge prediction. Despite the 43 datasets and 16 evaluation metrics used, there is still need for a Legal NLP model that is trained primarily on Indian Legal corpus as all existing models are trained on EU, US or Chinese corpora. Black box nature of the output leads to low \emph{interpretability} which is contrary to the justification based legal landscape. Prison term prediction remains suboptimal (e.g., 42.55 MaR in few-shot settings) due to data distribution challenges. Out of 36 official global languages, support is missing for 27 of them. Only uses judgement summaries and not raw evidence.


A Hybrid 2 stage model that includes RobERTa+DGCNN(stage 1) and T5 PEGASUS (stage 2) was used to create summary of Legal news\cite{b2}. The 1st stage is used to extract sentences and given a vector representation that contains critical information by using the Stage 1 models in conjunction with Average Pooling layer for rapid text vectorisation. DGCNN takes the dimensionality reduced vector representation of extracted sentences. The 2nd layer model(T5) takes the encoded vector, passes them through a Dense layer to produce a single embedding vector (short summary). ROUGE (Recall-Oriented Understudy for Gisting Evaluation) was used as the evaluation measure. The model was found to be effective in summarizing relatively short Legal articles, it displayed a limited ability extract deep/full context (arguments, entities) from longer/complex inputs.





A circumstance aware LJP framework known as NeurJudge was proposed to assist judicial decision making by separating crime facts into adjudicating, statutory and discretionary circumstances to better model what decisions are suitable\cite{b3}. The system introduces a novel approach called Circumstances of Crime aware Fact Separation (CCFS) to extract the facts from the input. An improved model NeurJudge+ utilises graph-based embeddings to distinguish articles/charges that are similar/intertwined. The summaries produced by the model are easy to interpret. The high computational cost coupled with the dataset’s reliance only on Chinese legal corpora make it difficult to directly transfer to Indian Legal landscape. The model struggles with verdict and sentencing when 2 articles are applicable which have high descriptive similarity. Due to the Black box nature it lacks explainability/ interpretability.


A comparison between Word2vec and BERT models was performed while using UDA (Unsupervised Data Augmentation); combining labelled and un-labelled data to increase robustness \cite{b4}. The dataset is scarce and was sourced from the Brazilian Prosecutor’s office’s records, leading to overfitting in BERT. After implementing UDA for Data Augmentation, the Accuracy of both models jumped from 80.7\% to 92\%. The main drawback is the use of Synthetic dataset to augment the model; the resulting performance may not fully generalize to real-world legal scenarios. Small claims court have verbose case descriptions which are constrained heavily by the 512 token limit of BERT models.


BART, Random Forest and LIME(XAI) are used in conjunction with each other to help provide both Summarization, IPC Prediction and Verdict Prediction respectively for the Document. A summary of 150 tokens is generated from a document of max length 1024 tokens\cite{b5} resulting in an accuracy of ~97\%. LIME is incorporated to improve explainability and transparency. However, due to the use of both BART and LIME complexity and computational overhead increases. Using max length of 1024 tokens consumes large amounts of VRAM, whereas limiting to 512 tokens provides comparable performance.

An Ontology-driven knowledge-block summarization method for Chinese judgment document classification was proposed. Domain ontologies and top-level legal ontologies are merged to extract three core blocks: objective facts, subjective intent, and judgment results. The system\cite{b6} uses Word2Vec embeddings, JieBa tokenizer (for Mandarin only) and Word Mover’s Distance (WMD) to compute similarities between extracted blocks, followed by a KNN classifier. Using specific blocks and not entire documents increases both accuracy and speed. However, it requires high quality Ontologies and is linguistically dependent on Chinese corpora only, limiting its transferability between jurisdictions such as India. WMD requires high computational overhead standard models such as Bag of Words, TF-IDF fail to capture document structure and legal semantics in depth.
In line with the UN’s Sustainable Development Goals (SDGs) an ensemble of SVM, Naïve Bayes and LSTM was used to create a system that can correctly label/classify court cases based on their type and what SDG they fall under\cite{b7}. Data augmentation and ensemble strategies were implemented to handle label imbalance between classes, however lack of data from the Brazilian Supreme Court, led to overfitting. All metrics such as Accuracy and F1 score peaked at a stable ~0.80. This model performs effectively when important keywords are present but cannot infer deeper contextual relationships due to the small and restrictive nature of the dataset. SDG model relies heavily on case law/precedents leading to higher complexity and low reliability on cases that do not match any precedents while also being limited to one language (Portuguese).



A text-importance similarity matching framework was proposed to improve long document legal case retrieval. A novel Unsupervised clustering and Contrastive learning approach that identified and preserved only the most critical and factual sentences was created\cite{b8}. These extracted facts were then fed into a BERT based encoder to find Similarity score between Legal documents. Cluster-center distance is used to quantify the impact of each extracted fact; allowing the system to surpass the 512 token limit of the BERT based models. Integrating triplet based contrastive learning and center loss to better differentiate between cases, a final accuracy of 75.08\% was achieved. The system works effectively on larger inputs but is restricted to Chinese Legal corpora and non-transferrable due to differences in Jurisdictions and Language as well as the traditional 512 token limit of BERT models, that cannot be overcome in Indian Legal corpus, unless Contrastive learning is applied. Lower quality of the initial unsupervised clusters can cascade into low accuracy, increase inference latency and event sequence disruption.



A Transformer based ECHR case classification framework was proposed to automate the detection of Human rights violations from extremely large Court judgements. A Sliding-window text sequence expansion technique is used to exceed the 512 token limit for BERT based models such as RoBERTa, Legal-BERT, BigBird, ELECTRA. RoBERTa performed the best in the Binary violation classification(F1 score of 86.7\%), whereas for multi-class classification BigBird outperformed all other models with an F1 score of 78.1\% \cite{b9}.Although, the Sliding window approach allows for the BERT based models to exceed their token limits and process larger documents, it incurs high computational overhead and is overdependent on English corpus with good metadata. Adding extra case features such as court branch, importance score leads to diminishing returns due to the text content dominating the feature space. DAPT on LegalBERT and BigBird remains as a point of improvement(unexplored here).


A large scale Bangla NLP Legal corpus named KUMono was created by Web scraping 1.3 million articles across 18 different categories. It contains 353 million word tokens and 1.68 million unique tokens to address the pressing need for a Bangla language corpus. This corpus was further enhanced by using TF-IDF for Article categorization. 6 NLP/ML models were utilised to classify the Court cases present; highest accuracy was achieved by Random Forest and Decision Tree Classifiers with performance metrics exceeding 0.98(Precision, Recall and F1 score) \cite{b10}. KUMono has a large scale, but it lacks context and depth due to dependence on web scraping. Transformer models such as BERT are superior for the purpose of summarization/comparison. The system is also limited to the Bangla corpus with minimal Arabic coverage. Dataset size is low despite Bangla being the 7th most spoken language worldwide.




An SCM (Similar Case Matching) system was developed to enhance long document parsing and similarity matching using a fine-tuned LegalBERT encoder combined with a Dual attention architecture. Local self-attention was used to extra important intra-sentence features, Global attention was used to extract broader context between multiple documents\cite{b11}. The dual attention mechanism allowed the system to outperform existing systems on Cosine, Manhattan and Jaccard metrics. Trained on CAIL+SCM datasets the system was found to have good recall and an accuracy of 89.5\% for Criminal cases and 90.2\% for Civil cases. The dual attention architecture and complex fine-tuning of LegalBERT(12 layers) led to significant computational overhead. The system is limited to Chinese corpora only. The network model lacks semantic depth interaction for Siamese. Usage of basic word frequency model leads to failure in capturing legal jargon and local key features in larger documents.	


Legal NLP is classified into 3 main categories/tasks: Legal Search (retrieval, entailment, QA), Legal Document Review (NER, similarity, classification, summarization), and Legal Prediction—showing that domain-specific models like LEGAL-BERT, LamBERTa, BureauBERTo, ConfliBERT consistently outperform general LLMs such as ChatGPT\cite{b13}. Domain Adaptive Pre-Training (DAPT) on relevant Legal corpora allows smaller NLP models to outperform LLMs and achieve competitive performance for the above 3 tasks with an F1 gain of 7.2\%.  DAPT on legal dataset provides an F1 gain ranging from 15.4\% to 18.2\% as compared to DAPT on generic dataset. The computational cost of specialized NLP models is lower than LLMs but are found to be inferior in long context/large input documents, generalization across jurisdictions (Indian, Chinese, EU, USA, etc) and dataset diversity/size.
A cross-domain LJP frameworks named JurisCTC was proposed to overcome data scarcity in Criminal law by transferring knowledge from Civil law datasets using Unsupervised Data Augmentation (UDA) and Contrastive learning \cite{b14}. A BERT encoder is combined with a class and domain classifier through a Gradient Reversal layer to optimize Maximum Mean Discrepancy (MMD). The system achieves a substantial accuracy of 76.59\% on Criminal law alongside a 78.83\% on Civil law by learning domain invariant representations, The system has very strong generalisation due to UDA, but it is limited only to Chinese Legal corpora and incurs high computational cost for adversarial BERT training. JurisCTC has a higher rate of false positives in the context of criminal cases and trails behind GPT4.0 (75.92\% vs. 83.00\%) for the same. It also requires substantial manual intervention for feature engineering.



Keynote highlights the rapid progress and evolution in NLP, explaining the range of subtasks from basic pre-processing to NER, text similarity, QA, summarization, sliding sequence window, etc. A notable example is the Multi-lingual Legal NLP model developed for Swiss Federal court that can handle 20 different Languages\cite{b15}. Domain pre-trained NLP models such as BERT can provide performance equivalent or surpassing general LLMs with exponentially higher compute power, provided the 5 components: architecture, hyperparameters, training data, model weights/checkpoints, and source code are kept fully open Source. Private firms have an advantage when it comes to powerful models that can handle multiple legal case types, the model in question here required an investment of \$30 million which is infeasible for individuals or smaller teams.



An LJP system named KEMCAN was proposed, utilising a multi-cross attention architecture. The system incorporates legal charge knowledge (definitions, subjective/objective elements, etc) with the fact description to better differentiate between the similar charges/penal codes mentioned in the text\cite{b16}. The system encodes both fact sentences and knowledge units using Bi-GRU + Attention mechanism, mapping each sentence with relevant legal information. The system was able to outperform models such as NeurJudge\cite{b3}, LADAN, BERT-Crime, etc, with a F1 score difference between +3.22\% to +6.5\% over these models. KEMCAN is effective at understanding context but requires a manually refined dataset while also being limited to Chinese criminal legal corpus. KEMCAN was focused primarily on applicable articles and charges, while ignoring the critical subtasks such as prison sentence.


LASG is a legal document summarization framework that was proposed to streamline judicial document analysis by incorporating CKIP transformers (Chinese BERT for sentence embedding) with a PageRank based re-ranking algorithm to extract most representative/important sentences from the documents \cite{b17}. Semantic similarity of extracted facts is computed via cosine similarity after which PageRank is applied to select the top/k-most important sentences to be part of the summary. LASG outperforms BERTSUM and vanilla CKIP transformers and achieves high performance metrics on ROGUE2 (12.72), ROUGE-L (18.33), etc. The system is efficient, lightweight and easy to deploy but is dependent on CKIP transformer. The summaries generated might not encompass the full depth of the corpus. The model lacks domain-specific customization/fine-tuning for different legal case types leading to lack of contextual depth due to being trained primarily on criminal cases. Hallucinations are also a major setback due to the abstractive LLMs.



A legal text classifier was developed to classify petitions for Brazil’s Public Prosecutor’s Office. This study compared TF-IDF, Word2Vec, SVM, Logistic Regression, Decision trees, CNNs, RNNs, and it was found that Word2Vec combined with LSTM encoder achieved the highest performance at 90.47\% Accuracy and F1 score of 85.49\%\cite{b18}, across 18 legal classes and 922,000 cases. This approach offered better semantic generalization relative to traditional bag-of-words models. However, TF-IDF was found to be more effective for simpler classifier models and smaller, more domain-specific datasets, albeit with limited context capacity than BERT based models. Random Under-Sampling (RUS), Over-Sampling were restricted due to computational constraints. 





A systematic study of all NLP/LLM systems found that domain-specific transformer-based NLP models such as BERT can outperform general purpose LLMs while also requiring substantially lower computation resources\cite{b19}. By using DAPT\cite{b13}, Contrastive learning\cite{b8} \cite{b14}, Dual attention architectures\cite{b11}. the F1 score of specialised NLP models such as Legal-BERT can be increased by 8-15\% over a generic LLM. Using techniques such as Sliding sequence window, the 512 token limitation\cite{b9} of traditional BERT models can also be overcome. The models also require high cost expert annotated judgements for reference.


LegalRAG is a RAG (Retrieval Augmented Generation) based framework designed for low-resource legal documents for the Bangla corpus. It compares and utilizes Llama3.2(3B) and Llama3.1(8B) wherein the cosine similarity increases from 0.76 to 0.82 when transferring from the former to the latter\cite{b20}. The dataset is augmented by using RAG to add relevant data scraped from external web sources. Due to the scarcity of the Bangla corpus, synthetic data was used to augment the overall dataset. The system has high accuracy for Bangla/English corpus but is constrained due to the low dataset size and unavailability of relevant data to scrape. The system exhibits overfitting lack of DAPT and overall low resource nature of the dataset. The usage of synthetic data leads to poor out of context vulnerability, closed loop bias and computational latency trade-offs.


Pre-trained Language Models (PLMs) across 8 legal datasets were evaluated and it was observed that they outperformed non-PLM models by 4\%-35\% on most NLP tasks. Domain specific models such as LegalBERT were the only models that could surpass the performance of PLMs\cite{b21}, achieving marginal performance gains of 2\%-5\%. PLMs demonstrated strengths in handling legal terminology, complex reasoning and better recall for multi-label tasks. However, they underperformed by 5\% or more in regards to cross-domain transferability and limited to a 512 token length.  Domain specific PLMs also exhibited limited transferability between different legal sub-domains. Diminishing returns in F1 score were exhibited when processing larger legal documents; 1.5\% gain in F1 score required 7 times longer training. PLM retrieval suffered from low accuracy due to difficulty in handling shared keywords that are legally irrelevant which lead to a gap in legal semantic matching.


HANOI-Legal is a parallel learning framework that adapts Pre-trained Language Models (PLMs) using Uniprompt; a unified QA style prompting scheme that reformulates diverse datasets into a single text-to-text format. Built on an encoder-decoder PLM(Randeng-T5-784M) \cite{b22}, the system performs unified prompt-based fine tuning yielding strong gains; +22.13\% F1 on CivilEE-CLS dataset and +46.35\% and +41.46\% on CivilEE-Args and CJRC datasets, respectively. However, the performance of the system is constrained by the relatively small size of the T5 model. HANOI performs best in data-scarce environments only, in resource rich environments other models surpass it. HANOI framework’s scalability for larger models (100B+ parameters) is unpredictable. 





An NLP model was created to predict the outcomes of Philippines SC corpora. The system incorporated bag of words n-grams with spectral clustering-based classifiers alongside popular classifiers such as SVM and Random Forest. The dataset was small and included approximately 6,500 cleaned and metadata tagged SC cases. SVM with n-grams had an accuracy of 45\%; improved to 55\% with topic-cluster features\cite{b23}. The best performance was provided by Random Forest classifier with topic-cluster features at 59\%. The models were simple and computationally light, but due to the small dataset and lack of standardized legal document format significantly hindered the performance of the models. Bag of words model is insufficient for extracting abstract legal reasoning due to courts focusing on “questions of law” rather than “questions of facts”.





An NLP summarization model was created for the Turkish Constitutional Court decisions that utilised an expertly annotated 1300 case dataset fed to a BERT2BERT model to produce summaries and verdict prediction was performed using XGBoost. The extractive-abstractive nature of the models enabled it to circumvent the 512 token limit of BERT. The XGBoost model was able to attain a 93.84\%\cite{b24} accuracy when fed full texts and 62.30\% accuracy when fed BERT generated summaries. The main advantage of this Hybrid approach was high accuracy of prediction and summarization with relatively low computational cost in part due to the smaller dataset. However, due to the small dataset and its need to be annotated by experts, scalability is challenging due to the computational overhead of BERT2BERT. The model is limited to Constitutional court, and does not generalize well for Criminal and Administrative laws. The models lack transparency and there is a need to introduce XAI to improve interpretability.



Transformer based models (BERT) were compared with LLMs (Llama) to evaluate their effectiveness for summarizing Portuguese legal documents. A highly annotated and expertly curated dataset of 2,373 documents was used as the evaluation base. LegalBERT and BERT-TRJ were compared with Llama3.1(70B) and Gemma2(27B) for the NER task. The fine-tuned BERT models had the highest F1 score lying between 0.74-0.96\cite{b25}; outperforming LLMs due to their higher token-level precision. Llama3.1 was tested in a zero-shot method and achieved a peak F1 score of 0.93. Due to the imbalance in dataset and small size; generalization was limited. The LLMs could not handle complex, multi-span legal entities. Confidentiality constraints surrounding source documents and expert annotations led to issues with reproducibility. Gemma2 extracted excessive amounts of irrelevant information and also suffered from hallucinations.


\vspace{6pt}




\pagebreak
\section*{Tabular Summary of Reviewed Studies}
{\renewcommand{\arraystretch}{1.4}
\setlength{\tabcolsep}{6pt}
\footnotesize
\begin{longtable}{|p{0.19\textwidth}|p{0.15\textwidth}|>{\raggedright\arraybackslash}p{0.24\textwidth}|>{\raggedright\arraybackslash}p{0.19\textwidth}|>{\raggedright\arraybackslash}p{0.18\textwidth}|}
\caption{Summary of key prior research on NLP models and LLMs for Legal corpora.}
\label{tab:litreview}\\
\hline
\textbf{Title (Year)} & \textbf{Authors} & \textbf{Key Findings} & \textbf{Gaps / Limitations} & \textbf{Relevance / Context} \\ \hline
\endfirsthead

\multicolumn{5}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\textbf{Title (Year)} & \textbf{Authors} & \textbf{Key Findings} & \textbf{Gaps / Limitations} & \textbf{Relevance / Context} \\ \hline
\endhead

\hline \multicolumn{5}{r}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot
A Survey on Legal Judgment Prediction: Datasets, Metrics, Models and Challenges (2023)~\cite{b1} & 
J. Cui, X. Shen, and S. Wen & 
Domain-specific PLMs and Longformer models (e.g., Lawformer) outperform generic LLMs in LJP tasks, achieving up to 96.6\% accuracy in charge prediction by capturing long-distance dependencies. & 
Existing models lack training on Indian Legal corpora, suffer from ``black box'' interpretability issues, and show suboptimal performance in prison term prediction and multilingual support. & 
The digitization of legal data enables Legal Judgment Prediction (LJP) to enhance judicial efficiency through automated summarization and verdict prediction. \\ \hline


A Legal News Summarisation Model Based on RoBERTa, T5 and Dilated Gated CNN (2023)~\cite{b2} & 
W. Qin and X. Luo \& Luo, X. & 
A hybrid architecture using RoBERTa+DGCNN for extraction and T5-PEGASUS for abstraction effectively summarizes legal news using ROUGE as a primary metric. & 
Limited ability to extract deep context or complex arguments from longer inputs. & 
Employs a two-stage approach—vectorization and dense-layer embedding—to streamline the generation of concise summaries for legal news articles. \\ \hline


A Circumstance-Aware Neural Framework for Explainable Legal Judgment Prediction (2024)~\cite{b3} & 
L. Yue, Q. Liu, B. Jin, H. Wu, and Y. An & 
NeurJudge utilizes Circumstances of Crime aware Fact Separation (CCFS) and graph-based embeddings (NeurJudge+) to accurately model decisions and distinguish between intertwined charges. & 
High computational costs, lack of interpretability due to "black box" nature, and difficulty distinguishing between highly similar articles. & 
A circumstance-aware LJP framework that assists judicial decision-making by categorizing facts into adjudicating, statutory, and discretionary circumstances. \\ \hline


A Small Claims Court for the NLP: Judging Legal Text Classification Strategies With Small Datasets (2023)~\cite{b4} & 
M. Noguti, E. Vellasques, and L. S. Oliveira & 
Implementing Unsupervised Data Augmentation (UDA) increased accuracy from 80.7\% to 92\% for small datasets. & 
Use of synthetic data may prevent generalization to real-world legal scenarios; constrained by BERT's 512-token limit. & 
Examines strategies for legal text classification when data is scarce. \\ \hline


AI-Driven Prediction of Indian Criminal Case Outcomes (2024)~\cite{b5} & 
L. Boppana, H. Ranga, P. S. A. Pravallika, T. Thakre, and Y. Lakshmi & 
An ensemble approach utilizing BART and Random Forest achieves $\sim$97\% accuracy in IPC and verdict prediction, generating 150-token summaries from 1024-token inputs. & 
High VRAM consumption and computational overhead due to BART and LIME integration; performance at 1024 tokens is comparable to 512 tokens. & 
Incorporates Explainable AI (LIME) to improve transparency and explainability in the multi-task prediction of Indian criminal case outcomes. \\ \hline


An Ontology Driven Knowledge Block Summarization Approach for Chinese Judgment Document Classification (2018)~\cite{b6} & 
Y. Ma, P. Zhang, and J. Ma & 
Extracting specific ``knowledge blocks'' (facts, intent, results) via ontologies and Word Mover's Distance (WMD) increases classification accuracy and processing speed. & 
High linguistic dependence on Chinese corpora, high computational overhead for WMD, and the requirement for high-quality ontologies limit transferability. & 
Proposes an ontology-driven approach to capture document structure and legal semantics more deeply than traditional Bag of Words or TF-IDF models. \\ \hline

Automated Labelling of Judicial Controversies Before the Brazilian Supreme Court According to the Sustainable Development Goals (2023)~\cite{b7} & 
R. L. Canalli, et al. & 
An ensemble of SVM, Naïve Bayes, and LSTM achieved a stable $\sim$0.80 F1 score by using data augmentation to manage label imbalance. & 
Overfitting due to limited data, inability to infer deep contextual relationships beyond keywords, and heavy reliance on precedents. & 
Aligns judicial case classification with UN Sustainable Development Goals (SDGs); currently limited to Portuguese and Brazilian case law. \\ \hline


Chinese Legal Case Similarity Matching Based on Text Importance Extraction (2025)~\cite{b8} & 
A. Fan, S. Wang, and Y. Wang & 
Uses unsupervised clustering and contrastive learning to identify critical sentences and surpass the 512-token limit. & 
Lower quality of initial clusters can cause low accuracy and increased inference latency; currently restricted to Chinese corpora. & 
Proposes a text-importance similarity matching framework for long documents. \\ \hline


Classifying European Court of Human Rights Cases Using Transformer-Based Techniques (2023)~\cite{b9} & 
A. S. Imran, et al. & 
Sliding-window technique allows BERT to process large documents; RoBERTa achieved 86.7\% F1 in binary classification while BigBird excelled in multi-class tasks (78.1\% F1). & 
Sliding-window approach incurs high computational overhead; overdependent on English corpus; non-text features (importance scores) yield diminishing returns. & 
Automates detection of human rights violations in large judgments by extending BERT models beyond the 512-token limit. \\ \hline


Compilation, Analysis and Application of a Comprehensive Bangla Corpus KUMono (2022)~\cite{b10} & 
A. Akther, et al. & 
Random Forest and Decision Tree classifiers achieved $>$0.98 F1 scores in classifying court cases within a large-scale corpus of 1.3 million scraped articles. & 
Corpus lacks contextual depth due to web-scraping reliance; limited to Bangla with minimal Arabic coverage; relatively small for the language's global rank. & 
Addresses the scarcity of Bangla legal resources by providing 353 million tokens across 18 categories to facilitate legal article categorization. \\ \hline


Deep Text Understanding Model for Similar Case Matching (2024)~\cite{b11} & 
J. Xiong and Y. Qiu & 
A Dual Attention architecture (Local and Global) combined with LegalBERT achieved $\sim$90\% accuracy in civil and criminal cases. & 
12-layer fine-tuning incurs significant computational overhead; lacks semantic depth interaction; restricted to Chinese corpora. & 
Utilizes a hierarchical attention mechanism to extract both intra-sentence features and broader inter-document context. \\ \hline


Exploring LLMs Applications in Law: A Literature Review on Current Legal NLP Approaches (2025)~\cite{b13} & 
M. Siino, et al. & 
Domain-specific models using DAPT consistently outperform general LLMs like ChatGPT with an F1 gain of 18.2\%. & 
Specialized models are inferior in long context handling and generalization across diverse jurisdictions. & 
Categorizes Legal NLP into Search, Document Review, and Prediction; highlights the efficiency of smaller, domain-adapted models. \\ \hline


JurisCTC: Enhancing LJP via Cross-Domain Transfer and Contrastive Learning (2025)~\cite{b14} & 
Z. Kang, et al. & 
Transfers knowledge from Civil to Criminal law using UDA and domain invariant representations, achieving 76.59\% accuracy on Criminal cases. & 
Higher rate of false positives in criminal cases; performance trails behind GPT-4 in specific tasks. & 
Proposes a cross-domain LJP framework to overcome data scarcity in Criminal law by transferring knowledge from Civil law datasets. \\ \hline


Keynote - AI for the Public Sector and the Case of Legal NLP (2023)~\cite{b15} & 
M. Stürmer & 
Open-source domain-specific models (like BERT) can match or surpass high-compute general LLMs when training components are transparent and domain-adapted. & 
High-end proprietary models require massive investment (e.g., $\sim$\$30 million), creating high barriers to entry for small teams and public institutions. & 
Highlights the evolution of NLP and emphasizes open-source's role in maintaining digital sovereignty and accessibility in the public legal sector. \\ \hline


Knowledge-Enriched Multi-Cross Attention Network for Legal Judgment Prediction (2023)~\cite{b16} & 
C. He, et al. & 
KEMCAN utilizes Bi-GRU and multi-cross attention to map facts to legal knowledge, outperforming models like NeurJudge by 3.22\% to 6.5\% in F1 score. & 
Requires a manually refined dataset; limited to Chinese criminal law; ignores prison sentence subtasks. & 
Incorporates legal charge knowledge (definitions and elements) directly into the fact description to differentiate between confusing penal codes. \\ \hline


LASG: Streamlining Legal Adjudication with AI-Enabled Summary Generation (2024)~\cite{b17} & 
Y. Liu and Y. Lin & 
LASG outperforms BERTSUM by using CKIP transformers and PageRank re-ranking, achieving ROUGE-L scores of 18.33 through cosine similarity filtering. & 
Summaries may lack full depth; the model lacks domain-specific fine-tuning and is prone to abstractive hallucinations. & 
A lightweight, efficient extractive-summarization framework designed to streamline judicial analysis by identifying representative sentences. \\ \hline


Legal Document Classification: An Application to Law Area Prediction of Petitions (2020)~\cite{b18} & 
M. Y. Noguti, et al. & 
Word2Vec with an LSTM encoder achieved 90.47\% and 85.49\% F1 scores across 18 legal classes and 922,000 cases. & 
TF-IDF is effective for simple models or small datasets but lacks the context-capture capacity of transformer-based architectures. & 
Compares traditional ML and DL models for classifying petitions for the Brazilian Prosecution Office. \\ \hline


Legal Natural Language Processing From 2015 to 2022: A Systematic Mapping Study (2024)~\cite{b19} & 
E. Quevedo, et al. & 
Specialized NLP models (Legal-BERT) using DAPT and contrastive learning increase F1 by 8--15\% over generic LLMs. & 
Specialized models still require high-cost, expert-annotated judgments for training and reference. & 
Confirms that domain-specific BERT models outperform general LLMs with lower resources and overcome token limits via sliding-window techniques. \\ \hline


LegalRAG: A Hybrid RAG System for Multilingual Legal Information Retrieval (2025)~\cite{b20} & 
M. R. Kabir, et al. & 
Utilizing Llama 3.1 (8B) increased cosine similarity to 0.82, outperforming the 3B model in a RAG-based pipeline for low-resource languages. & 
Synthetic data usage leads to closed-loop bias, overfitting, and computational latency. & 
Addresses data scarcity in the Bangla legal domain through Retrieval-Augmented Generation (RAG). \\ \hline


On the Effectiveness of PLMs for Legal NLP: An Empirical Study (2022)~\cite{b21} & 
D. Song, et al. & 
PLMs outperform non-PLM models by 4\%--35\%; LegalBERT achieves marginal gains in legal terminology and reasoning. & 
Poor cross-domain transferability and 512-token limit; 1.5\% F1 gain requires 7x longer training (diminishing returns). & 
Evaluates PLM effectiveness across 8 legal datasets, noting strengths in complex reasoning and recall. \\ \hline


Parallel Learning for Legal Intelligence: A HANOI Approach (2024)~\cite{b22} & 
Z. Song, et al. & 
Utilizing Randeng-T5-784M with unified prompting yielded massive F1 gains (+46.35\% on CivilEE-Args and +41.46\% on CJRC datasets). & 
Constrained by relatively small model size (T5); performance on 100B+ parameter models remains unpredictable. & 
Proposes the HANOI framework using ``UniPrompt'' to reformulate diverse legal tasks into a single text-to-text format. \\ \hline


Predicting Decisions of the Philippine Supreme Court using NLP and ML (2018)~\cite{b23} & 
M. B. L. Virtucio, et al. & 
Random Forest with topic-cluster features achieved 59\% accuracy, outperforming SVM with n-grams (45\%) on 6,500 cases. & 
Bag-of-words models are insufficient for abstract legal reasoning; hindered by lack of standardized formats and small dataset size. & 
Explores outcome prediction in the Philippines SC corpora with limited data and computationally light classifiers. \\ \hline


Summarization, Prediction, and Analysis of Turkish CC Decisions with XAI and a Hybrid NLP method (2025)~\cite{b24} & 
T. Turan and E. U. Küçüksılle & 
Hybrid BERT2BERT and XGBoost approach attained 93.84\% accuracy for verdict prediction; used an extractive-abstractive method to bypass 512-token limits. & 
Scalability is challenging due to the need for expert annotation; limited to Constitutional Court cases and lacks interpretability. & 
Combines extractive-abstractive summarization with Explainable AI (XAI) for Turkish Constitutional Court decisions. \\ \hline


Using Language Models for Extracting Legal Decisions from Portuguese Consumer Law Texts (2025)~\cite{b25} & 
S. Vasquez, et al. & 
Fine-tuned BERT models (F1 0.74--0.96) outperform LLMs like Llama 3.1 and Gemma 2 in NER tasks. & 
LLMs suffered from hallucinations and extracted excessive irrelevant information during zero-shot evaluation. & 
Evaluates BERT-based models vs. zero-shot LLMs (Llama 3.1, Gemma 2) using a curated dataset of 2,373 Portuguese legal documents. \\ \hline

\end{longtable}}

\noindent The studies summarized in Table~\ref{tab:litreview} collectively indicate that interaction fidelity, physiological engagement monitoring, and gamification significantly influence driver training outcomes and user vigilance. These insights directly inform the system design of the proposed VR-based driving simulator presented in Chapter~\ref{ch:system_analysis}.





\newpage

\section{Research Gap Analysis}\label{sec:gap_analysis}

Based on the comprehensive literature review, several critical research gaps have been identified in the current state of VR-based driving simulation and training systems:

\subsection{Hardware and Physical Interaction Fidelity for LPA}
\textbf{Gap 1: High VRAM and Computational Overhead.} Several high-performing models, such as those using 1024-token \cite{b5} inputs or dual attention architectures, consume excessive VRAM and require significant computational power.

\textbf{Gap 2: Inference Latency.} Complex models and specific similarity measures like Word Mover’s Distance (WMD) \cite{b6} suffer from high inference latency \cite{b8}, hindering real-time application.

\textbf{Gap 3: Adversarial Training Costs.} Advanced frameworks like JurisCTC \cite{b14} incur high computational costs specifically for adversarial BERT training.

\textbf{Gap 4: Scalability Infrastructure.} There is a lack of predictable infrastructure for scaling specialized legal models to larger (100B+ parameter) \cite{b22} architectures.



\subsection{Methodological and Sample Limitations}
\textbf{Gap 5: Jurisdictional and Geographic Bias:.} A significant majority of reviewed studies~\cite{Muguro2023,Qadir2019,Xu2022,Schultheis2005,Chung2022} A critical gap exists for models trained on Indian Legal corpora, as the majority of current research focuses on US, EU, or Chinese datasets \cite{b6}  \cite{b8}  \cite{b11}  \cite{b16}.

\textbf{Gap 6: Data Scarcity and Overfitting.} Many systems suffer from overfitting \cite{b4}  \cite{b7} \cite{b20} due to small, restrictive datasets, such as those sourced from specific prosecutor offices or Supreme Courts with limited case counts.	

\textbf{Gap 7: Synthetic Data Generalization.} The heavy reliance on synthetic data to augment small datasets \cite{b4} \cite{b20} leads to concerns that model performance will not generalize to real-world legal scenarios.

\textbf{Gap 8: Imbalanced Data Distribution.} Challenges in data distribution, particularly label imbalance \cite{b7} \cite{b25}, lead to suboptimal results in niche tasks like prison term prediction.

\subsection{Pedagogical and Training Effectiveness}
\textbf{Gap 9: Lack of Domain-Specific Customization.} Many models lack fine-tuning for specific legal sub-domains \cite{b17} \cite{b21} (e.g., transitioning from Criminal to Administrative law), leading to a lack of contextual depth.

\textbf{Gap 10: Diminishing Returns in Training.} There is a significant efficiency gap where marginal gains in F1 score (e.g., 1.5\%) require exponentially longer training times \cite{b9} \cite{b21} (e.g., 7x).

\textbf{Gap 11: Annotation Dependency.} The effectiveness of these models is highly dependent on expert-annotated judgments \cite{b19} \cite{b24} \cite{b25}, which are expensive and difficult to scale.


\textbf{Gap 12: Failure in Abstract Reasoning.} Traditional training methods like "Bag of Words" fail to capture abstract legal reasoning \cite{b6} \cite{b18} \cite{b23}, focusing too much on "questions of fact" rather than "questions of law".


\subsection{Technical and Realism Constraints}
\textbf{Gap 13: The 512-Token Limitation.} Standard BERT-based models are constrained by a 512-token limit \cite{b4} \cite{b8} \cite{b9} \cite{b21} \cite{b24}, which is insufficient for verbose legal documents and complex case descriptions.

\textbf{Gap 14:	Hallucinations and Reliability.} Abstractive LLMs used for summarization suffer from hallucinations\cite{b17} \cite{b25}, which is a major setback in a high-stakes legal environment.

\textbf{Gap 15: Semantic Depth and Jargon.} Basic models often fail to capture complex legal jargon \cite{b10} \cite{b11} \cite{b17} required for deep semantic matching.

\textbf{Gap 16: Black Box Nature.} A lack of transparency and explainability \cite{b1} \cite{b3} in many models prevents them from being used in a justification-based legal landscape.


\subsection{Regulatory, Ethical, and Commercialization Gaps}
\textbf{Gap 17: Financial Entry Barriers.} The extreme cost of developing powerful multi-case legal models (e.g., \$30 million) \cite{b15} creates a commercialization gap for smaller teams and public sector entities.

\textbf{Gap 18: Confidentiality and Reproducibility.} Constraints regarding source document confidentiality and protected expert annotations \cite{b19} \cite{b24} \cite{b25} often lead to significant issues with research reproducibility.

\textbf{Gap 19: Multilingual Support Gaps.} There is a massive regulatory and accessibility gap, with support missing for 27 out of 36 official global languages \cite{b1}.

\textbf{Gap 20: Closed-Loop Bias.} The use of RAG and synthetic augmentation can lead to closed-loop biases \cite{b20}, where models reinforce their own errors rather than learning from diverse, objective evidence.

\subsection{Summary of Research Gaps}
The identified gaps highlight five overarching themes requiring urgent research attention:
\begin{enumerate}
    \item \textbf{Computational efficiency and scalability,} as many state-of-the-art legal models demand excessive VRAM, incur high inference latency, and rely on costly training pipelines.
    \item \textbf{Jurisdictional and dataset limitations,} including heavy bias toward non-Indian legal systems, data scarcity, synthetic-data overreliance, and severe label imbalance.
    \item \textbf{Limited legal reasoning and pedagogical depth,} marked by poor abstraction, overdependence on expert annotations, and weak transfer across legal sub-domains.
    \item \textbf{Technical realism and trustworthiness deficits,}  such as token-length constraints, hallucinations in abstractive models, inadequate handling of legal jargon, and black-box behavior.
    \item \textbf{Regulatory, ethical, and accessibility barriers,} including high development costs, confidentiality-driven reproducibility issues, and insufficient multilingual support.
\end{enumerate}

\noindent The proposed Legal Precedent Assistant for Indian Family Courts, built using LegalBERT for structured semantic representation and LLaMA-3.1 for long-context reasoning and explanation, directly addresses Gaps 2, 3, and 4, and partially mitigates Gaps 1 and 5. By narrowing the domain to family-law jurisprudence, leveraging weak supervision and domain-adaptive pretraining on Indian judgments, and employing explainable, modular inference pipelines, the system enables cost-effective, jurisdiction-aware, and interpretable legal decision support. Subsequent chapters detail the architecture, training strategy, and evaluation framework designed to bridge these critical research gaps within realistic academic and infrastructural constraints.